{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a459f5a0",
      "metadata": {},
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "05b75455",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "import mock_d2l_jax as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6886858",
      "metadata": {
        "origin_pos": 1
      },
      "source": [
        "# Network in Network (NiN)\n",
        ":label:`sec_nin`\n",
        "\n",
        "LeNet, AlexNet, and VGG all share a common design pattern:\n",
        "extract features exploiting *spatial* structure\n",
        "via a sequence of convolutions and pooling layers\n",
        "and post-process the representations via fully connected layers.\n",
        "The improvements upon LeNet by AlexNet and VGG mainly lie\n",
        "in how these later networks widen and deepen these two modules.\n",
        "\n",
        "This design poses two major challenges. \n",
        "First, the fully connected layers at the end\n",
        "of the architecture consume tremendous numbers of parameters. For instance, even a simple\n",
        "model such as VGG-11 requires a monstrous $25088 \\times 4096$ matrix, occupying almost\n",
        "400MB of RAM. This is a significant impediment to speedy computation, in particular on\n",
        "mobile and embedded devices. Second, it is equally impossible to add fully connected layers\n",
        "earlier in the network to increase the degree of nonlinearity: doing so would destroy the\n",
        "spatial structure and require potentially even more memory.\n",
        "\n",
        "The *network in network* (*NiN*) blocks of :cite:`Lin.Chen.Yan.2013` offer an alternative,\n",
        "capable of solving both problems in one simple strategy.\n",
        "They were proposed based on a very simple insight: (i) use $1 \\times 1$ convolutions to add\n",
        "local nonlinearities across the channel activations and (ii) use global average pooling to integrate\n",
        "across all locations in the last representation layer. Note that global average pooling would not\n",
        "be effective, were it not for the added nonlinearities. Let's dive into this in detail.\n",
        "\n",
        "\n",
        "## (**NiN Blocks**)\n",
        "\n",
        "Recall :numref:`subsec_1x1`. In it we discussed that the inputs and outputs of convolutional layers\n",
        "consist of four-dimensional tensors with axes\n",
        "corresponding to the example, channel, height, and width.\n",
        "Also recall that the inputs and outputs of fully connected layers\n",
        "are typically two-dimensional tensors corresponding to the example and feature.\n",
        "The idea behind NiN is to apply a fully connected layer\n",
        "at each pixel location (for each height and width).\n",
        "The resulting $1 \\times 1$ convolution can be thought as\n",
        "a fully connected layer acting independently on each pixel location.\n",
        "\n",
        ":numref:`fig_nin` illustrates the main structural\n",
        "differences between VGG and NiN, and their blocks.\n",
        "Note both the difference in the NiN blocks (the initial convolution is followed by $1 \\times 1$ convolutions, whereas VGG retains $3 \\times 3$ convolutions) and in the end where we no longer require a giant fully connected layer.\n",
        "\n",
        "![Comparing architectures of VGG and NiN, and their blocks.](http://d2l.ai/_images/nin.svg)\n",
        ":width:`600px`\n",
        ":label:`fig_nin`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e2b1db8d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:19:57.972030Z",
          "iopub.status.busy": "2022-07-13T08:19:57.971564Z",
          "iopub.status.idle": "2022-07-13T08:19:59.955255Z",
          "shell.execute_reply": "2022-07-13T08:19:59.953973Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax import numpy as jnp, random, grad, vmap, jit\n",
        "from flax import linen as nn\n",
        "import optax\n",
        "# from d2l import jax as d2l\n",
        "\n",
        "\n",
        "def nin_block(out_channels, kernel_size, strides, padding):\n",
        "    return nn.Sequential([\n",
        "        nn.Conv(out_channels, kernel_size, strides, padding),\n",
        "        nn.relu,\n",
        "        nn.Conv(out_channels, kernel_size=(1, 1)), nn.relu,\n",
        "        nn.Conv(out_channels, kernel_size=(1, 1)), nn.relu])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67945f48",
      "metadata": {
        "origin_pos": 5
      },
      "source": [
        "## [**NiN Model**]\n",
        "\n",
        "NiN uses the same initial convolution sizes as AlexNet (it was proposed shortly thereafter).\n",
        "The kernel sizes are $11\\times 11$, $5\\times 5$, and $3\\times 3$, respectively,\n",
        "and the numbers of output channels match those of AlexNet. Each NiN block is followed by a max-pooling layer\n",
        "with a stride of 2 and a window shape of $3\\times 3$.\n",
        "\n",
        "The second significant difference between NiN and both AlexNet and VGG\n",
        "is that NiN avoids fully connected layers altogether.\n",
        "Instead, NiN uses a NiN block with a number of output channels equal to the number of label classes, followed by a *global* average pooling layer,\n",
        "yielding a vector of logits.\n",
        "This design significantly reduces the number of required model parameters, albeit at the expense of a potential increase in training time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cee4d238",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 1, 1, 3)\n"
          ]
        }
      ],
      "source": [
        "input_shape = (2, 4, 5, 3)\n",
        "x = random.normal(random.PRNGKey(0), input_shape)\n",
        "y = nn.avg_pool(x, (4, 5))\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a58df89a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:19:59.959721Z",
          "iopub.status.busy": "2022-07-13T08:19:59.959086Z",
          "iopub.status.idle": "2022-07-13T08:19:59.966802Z",
          "shell.execute_reply": "2022-07-13T08:19:59.965683Z"
        },
        "origin_pos": 6,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "class NiN(d2l.Classifier):\n",
        "    lr: float = 0.1\n",
        "    num_classes = 10\n",
        "    \n",
        "    def setup(self):\n",
        "        max_pool = lambda x: nn.max_pool(x, (3, 3), strides=(2, 2))\n",
        "\n",
        "        self.net = nn.Sequential([\n",
        "            nin_block(96, kernel_size=(11, 11), strides=(4, 4), padding=(0, 0)),\n",
        "            max_pool,\n",
        "            nin_block(256, kernel_size=(5, 5), strides=(1, 1), padding=(2, 2)),\n",
        "            max_pool,\n",
        "            nin_block(384, kernel_size=(3, 3), strides=(1, 1), padding=(1, 1)),\n",
        "            max_pool,\n",
        "            nn.Dropout(0.5, deterministic=False),\n",
        "            nin_block(self.num_classes, kernel_size=(3, 3), strides=1, padding=(1, 1)),\n",
        "            lambda x: nn.avg_pool(x, (1, 1)), # TODO: not sure what window size should be (global avg pooling)\n",
        "            d2l.flatten])\n",
        "        # self.net.apply(d2l.init_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "082be2df",
      "metadata": {
        "origin_pos": 7
      },
      "source": [
        "We create a data example to see [**the output shape of each block**].\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "4032d08f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:19:59.997620Z",
          "iopub.status.busy": "2022-07-13T08:19:59.996787Z",
          "iopub.status.idle": "2022-07-13T08:20:00.071459Z",
          "shell.execute_reply": "2022-07-13T08:20:00.070518Z"
        },
        "origin_pos": 8,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    params: {\n",
              "        net: {\n",
              "            layers_0: {\n",
              "                layers_0: {\n",
              "                    bias: (96,),\n",
              "                    kernel: (11, 11, 1, 96),\n",
              "                },\n",
              "                layers_2: {\n",
              "                    bias: (96,),\n",
              "                    kernel: (1, 1, 96, 96),\n",
              "                },\n",
              "                layers_4: {\n",
              "                    bias: (96,),\n",
              "                    kernel: (1, 1, 96, 96),\n",
              "                },\n",
              "            },\n",
              "            layers_2: {\n",
              "                layers_0: {\n",
              "                    bias: (256,),\n",
              "                    kernel: (5, 5, 96, 256),\n",
              "                },\n",
              "                layers_2: {\n",
              "                    bias: (256,),\n",
              "                    kernel: (1, 1, 256, 256),\n",
              "                },\n",
              "                layers_4: {\n",
              "                    bias: (256,),\n",
              "                    kernel: (1, 1, 256, 256),\n",
              "                },\n",
              "            },\n",
              "            layers_4: {\n",
              "                layers_0: {\n",
              "                    bias: (384,),\n",
              "                    kernel: (3, 3, 256, 384),\n",
              "                },\n",
              "                layers_2: {\n",
              "                    bias: (384,),\n",
              "                    kernel: (1, 1, 384, 384),\n",
              "                },\n",
              "                layers_4: {\n",
              "                    bias: (384,),\n",
              "                    kernel: (1, 1, 384, 384),\n",
              "                },\n",
              "            },\n",
              "            layers_7: {\n",
              "                layers_0: {\n",
              "                    bias: (10,),\n",
              "                    kernel: (3, 3, 384, 10),\n",
              "                },\n",
              "                layers_2: {\n",
              "                    bias: (10,),\n",
              "                    kernel: (1, 1, 10, 10),\n",
              "                },\n",
              "                layers_4: {\n",
              "                    bias: (10,),\n",
              "                    kernel: (1, 1, 10, 10),\n",
              "                },\n",
              "            },\n",
              "        },\n",
              "    },\n",
              "})"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rngs = {'params': random.PRNGKey(0), 'dropout': random.PRNGKey(1)}\n",
        "\n",
        "model = NiN()\n",
        "X = random.normal(random.PRNGKey(0), (1, 224, 224, 1))\n",
        "params = model.init(rngs, X)\n",
        "jax.tree_map(lambda x: x.shape, params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17595c4f",
      "metadata": {
        "origin_pos": 10
      },
      "source": [
        "## [**Training**]\n",
        "\n",
        "As before we use Fashion-MNIST to train the model.\n",
        "NiN's training is similar to that for AlexNet and VGG.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b546b346",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-13T08:20:00.078710Z",
          "iopub.status.busy": "2022-07-13T08:20:00.078103Z",
          "iopub.status.idle": "2022-07-13T08:23:49.070190Z",
          "shell.execute_reply": "2022-07-13T08:23:49.069003Z"
        },
        "origin_pos": 11,
        "tab": [
          "pytorch"
        ]
      },
      "outputs": [],
      "source": [
        "model = NiN(lr=0.05)\n",
        "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
        "data = d2l.FashionMNIST(batch_size=128, resize=(224, 224))\n",
        "# model.apply_init([next(iter(data.get_dataloader(True)))[0]], d2l.init_cnn)\n",
        "trainer.fit(model, data, rngs=rngs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "279f33b3",
      "metadata": {
        "origin_pos": 13
      },
      "source": [
        "## Summary\n",
        "\n",
        "NiN has dramatically fewer parameters than AlexNet and VGG. This stems from the fact that it needs no giant fully connected layers and fewer convolutions with wide kernels. Instead, it uses local $1 \\times 1$ convolutions and global average pooling. These design choices influenced many subsequent CNN designs.\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Why are there two $1\\times 1$ convolutional layers per NiN block? What happens if you add one? What happens if you reduce this to one?\n",
        "1. What happens if you replace the global average pooling by a fully connected layer (speed, accuracy, number of parameters)?\n",
        "1. Calculate the resource usage for NiN.\n",
        "    1. What is the number of parameters?\n",
        "    1. What is the amount of computation?\n",
        "    1. What is the amount of memory needed during training?\n",
        "    1. What is the amount of memory needed during prediction?\n",
        "1. What are possible problems with reducing the $384 \\times 5 \\times 5$ representation to a $10 \\times 5 \\times 5$ representation in one step?\n",
        "1. Use the structural design decisions in VGG that led to VGG-11, VGG-16, and VGG-19 to design a family of NiN-like networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "773c3ce0",
      "metadata": {
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ]
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/80)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "626d743d6476408aa1b36c3ff0d1f9d9d03e37c6879626ddfcdd13d658004bbf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
